#Coding:utf-8
"""
	Gestion de la base Local sqlite
"""
import json, re, datetime, time
from psycopg2 import sql

from pathlib import Path
import json, sys
from datetime import datetime, timedelta, timezone
import threading
import string,copy
import traceback

def normalize_table_name(base_name: str) -> str:
	base = re.sub(r"[^a-zA-Z0-9_]", "_", base_name.strip())
	return base

class local:
	def delete_all_from_DB(self):
		conn = self.get_conn()
		try:
			cur = conn.cursor()
			cur.execute("DROP SCHEMA public CASCADE;")
			cur.execute("CREATE SCHEMA public;")
			conn.commit()
			cur.close()
		finally:
			self.put_conn(conn)

	def success_response(self,data,where,action):
		return {
			"status":"ok",
			"data":data,
			"message":f'{action} {where} went successfully',
			"action":action,
			"where":where
		}
	
	def failed_response(self,data,where,action,E = None):
		if not E:
			E = traceback.format_exc()
			print(E)
		return {
			"status":"error",
			"data":data,
			"message":f'{action} {where} went wrong. \n this is what goes wrong:\n{E}',
			"action":action,
			"where":where
		}

	# =========================
	# CREATE TABLE
	# =========================
	def create_table(self, conn, base_table):
		today = datetime.utcnow().date()
		tomorrow = today + timedelta(days = 1)
		partition_name = f"{base_table}_{today.strftime('%Y_%m_%d')}"
		
		if base_table not in self.created_tables or partition_name not in self.created_tables:
			cur = conn.cursor()
			if base_table not in self.created_tables:
				cur.execute(
					sql.SQL("""
						CREATE TABLE IF NOT EXISTS {table} (
							id BIGINT GENERATED BY DEFAULT AS IDENTITY,
							data JSONB NOT NULL,
							updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
							PRIMARY KEY (id, updated_at)
						) PARTITION BY RANGE (updated_at)
					""").format(table = sql.Identifier(base_table))
				)

				idx_name = f"idx_{base_table}_updated_at"
				cur.execute(
					sql.SQL('''
						CREATE INDEX IF NOT EXISTS {idx}
						ON {table} (updated_at)
					''').format(
						idx = sql.Identifier(idx_name),
						table=sql.Identifier(base_table)
					)
				)
				self.created_tables.add(base_table)
			
			if partition_name not in self.created_tables:
				cur.execute(
					sql.SQL("""
						CREATE TABLE IF NOT EXISTS {partition}
						PARTITION OF {parent}
						FOR VALUES FROM (%s) TO (%s)
					""").format(
						partition = sql.Identifier(partition_name),
						parent = sql.Identifier(base_table),
						), (today, tomorrow)
				)
				self.created_tables.add(partition_name)
			
			conn.commit()
			cur.close()
			
		return 

	# ==========================
	# GET DATA
	# ==========================
	def _get_data(self, base_name, last_sync: datetime = None):
		t = time.time()
		conn = self.get_conn()
		try:
			real_table = normalize_table_name(base_name)
			self.create_table(conn, real_table)
			cur = conn.cursor()
			
			query = "SELECT id, data, updated_at FROM {table}"
			param = ()
			if last_sync:
				#print(last_sync)
				query += " WHERE updated_at > %s"
				param = last_sync,
			query += " ORDER BY updated_at ASC"
			cur.execute(sql.SQL(query).format(
				table = sql.Identifier(real_table)
				), param)
			rows = cur.fetchall()
			
			cur.close()
			tabs_dic = {}
			for row in rows:
				id = row[0]
				data = copy.deepcopy(row[1])
				update_at = row[2]
				data['updated_at'] = update_at.astimezone(timezone.utc).isoformat()
				tabs_dic[id] = data

			return tabs_dic
		except:
			print(traceback.format_exc())
			conn.rollback()
			return dict()
		finally:
			self.put_conn(conn)

	def _get_data_(self, base_name, last_sync, limit=500):
		real_table = normalize_table_name(base_name)
		conn = self.get_conn()
		cur = conn.cursor()

		query = """
			SELECT id, data, updated_at
			FROM {table}
			WHERE updated_at > %s
			ORDER BY updated_at ASC
			LIMIT %s
		"""

		cur.execute(
			sql.SQL(query).format(table=sql.Identifier(real_table)),
			(last_sync, limit)
		)

		rows = cur.fetchall()
		cur.close()
		self.put_conn(conn)

		return rows


	def get_data(self, base_name, last_sync:datetime = None):
		#try:
		#print(base_name,date)
		data = self._get_data(base_name)
		ret = self.success_response(data,date,'get')
		#print(ret)
		#except Exception as E:
		#	ret = self.failed_response("error",dict(),where,id,'get')
		return ret

	# ==========================
	# SAVE DATA
	# ==========================
	def save_data(self, base_name, data):
		real_table = normalize_table_name(base_name)

		#print(real_table,data)
		t = time.time()
		conn = self.get_conn()
		try:
			cur = conn.cursor()
			
			self.create_table(conn, real_table)
			cur.execute(
				sql.SQL("""
					INSERT INTO {} (data, updated_at)
					VALUES (%s, NOW())
					RETURNING id, updated_at
				""").format(sql.Identifier(real_table)),
				(json.dumps(data),)
			)
			row = cur.fetchone()
			conn.commit()
			cur.close()
			server_id = row[0]
			server_updated_at = row[1].astimezone(timezone.utc).isoformat()
			data['updated_at'] = server_updated_at
			data['id'] = server_id
			#print("ok")
			return self.success_response(data,real_table,'save')
		except:
			conn.rollback()
			return self.failed_response(data,real_table,"save")
		finally:
			self.put_conn(conn)

	# =============================
	# TABLE LIST
	# =============================
	def get_all_tabs_of(self, base_name):
		prefix = base_name.lower()
		conn = self.get_conn()
		cur = conn.cursor()

		cur.execute("""
			SELECT table_schema, table_name
			FROM information_schema.tables
			WHERE table_type = 'BASE TABLE'
			AND table_name ILIKE %s
			AND table_schema NOT IN ('pg_catalog', 'information_schema')
		""", (prefix + '%',))

		tables = cur.fetchall()
		cur.close()
		self.put_conn(conn)
		return tables
	
	def get_all_msg_of(self,base_name):
		tables = self.get_all_tabs_of(base_name)
		all_data = {}
		#print(tables)
		for ident in tables:
			sche, tab = ident
			#print(tab)
			msg_dic = self._get_data(tab,str())
			all_data[tab] = msg_dic
		return all_data

	# ==========================
	# DELETE ALL
	# ==========================
	def drop_tables(self, tables: tuple):
		"""
		tables = tuple de ('schema', 'table')
		ex: (('public','user_msg'), ('public','user_msg_log'))
		"""
		if not tables:
			print("Aucune table Ã  supprimer.")
			return

		conn = self.get_conn()
		conn.autocommit = True
		cur = conn.cursor()

		for schema, table in tables:
			try:
				query = sql.SQL("DROP TABLE IF EXISTS {}.{} CASCADE").format(
					sql.Identifier(schema),
					sql.Identifier(table)
				)
				cur.execute(query)
				print(f"ðŸ—‘ï¸ Table supprimÃ©e : {schema}.{table}")
			except Exception as e:

				print(f"{traceback.format_exc()}âŒ Erreur suppression {schema}.{table} -> {e}")

		cur.close()
		conn.close()

	def drop_all_tab_of(self,base_name):
		tables = self.get_all_tabs_of(base_name)
		self.drop_tables(tables)
		#tables = self.get_all_tabs_of(base_name)
		#print(tables)

	# ------------------
	def redo_ident(self,where):
		if where:
			p = "1234567890_"+string.ascii_lowercase
			th_txt = str()
			for i in where.lower():
				if i not in p:
					i = "xx"
				th_txt += i
			return th_txt
		return str()

	def _up_cache_local(self,where,data,id = None):
		with self._lock_dict.setdefault(where,threading.Lock()):
			tab_dic = self._local_cache.get(where,dict())
			if id:
				tab_dic[id] = data
			else:
				tab_dic.update(data)
			self._local_cache[where] = tab_dic


	
